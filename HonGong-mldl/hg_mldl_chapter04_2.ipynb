{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hg_mldl chapter04-2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUfK0DwTbysFWakNs/xA1h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gongboogi/SchoolWork/blob/main/HonGong-mldl/hg_mldl_chapter04_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**hg_mldl chapter 04-1**\n"
      ],
      "metadata": {
        "id": "CaRdNF85Um_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 확률적 경사 하강법\n",
        "매주 새로운 무작위의 데이터를 훈련하려면?\n",
        "\n",
        "-> 훈련한 모델을 버리지 않고 새로운 데이터에 대해서만 조금씩 더 훈련한다.\n",
        "= 점진적학습"
      ],
      "metadata": {
        "id": "EIfL4h5BU37w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**확률적 경사 하강법**: 대표적인 점진적 학습 알고리즘. 훈련세트에서 랜덤하게 하나의 샘플을 고른다.\n",
        "\n",
        "**에포크**: 훈련세트를 한 번 모두 사용하는 과정. 일반적으로 경사 하강법은 수십, 수백 번 이상 에포크를 수행한다.\n",
        "\n",
        "**손실함수(비용함수)**: 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지 측정하는 기준. 값이 작을수록 좋다!"
      ],
      "metadata": {
        "id": "xj3hF940aRdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rI9ERDCwfl2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**SGDclassifier**"
      ],
      "metadata": {
        "id": "3idTcfIgfhVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # fish_csv_data 파일에서 판다스 데이터프레임을 만듦\n",
        "fish = pd.read_csv('https://bit.ly/fish_csv')"
      ],
      "metadata": {
        "id": "EY_cbdOzWqf3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fish)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5lX0MmegUDz",
        "outputId": "e31cec0c-0404-4faa-ba38-1bc53ad14728"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Species  Weight  Length  Diagonal   Height   Width\n",
            "0     Bream   242.0    25.4      30.0  11.5200  4.0200\n",
            "1     Bream   290.0    26.3      31.2  12.4800  4.3056\n",
            "2     Bream   340.0    26.5      31.1  12.3778  4.6961\n",
            "3     Bream   363.0    29.0      33.5  12.7300  4.4555\n",
            "4     Bream   430.0    29.0      34.0  12.4440  5.1340\n",
            "..      ...     ...     ...       ...      ...     ...\n",
            "154   Smelt    12.2    12.2      13.4   2.0904  1.3936\n",
            "155   Smelt    13.4    12.4      13.5   2.4300  1.2690\n",
            "156   Smelt    12.2    13.0      13.8   2.2770  1.2558\n",
            "157   Smelt    19.7    14.3      15.2   2.8728  2.0672\n",
            "158   Smelt    19.9    15.0      16.2   2.9322  1.8792\n",
            "\n",
            "[159 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Species열을 제외한 나머지 5개는 입력데이터, Species열은 타킷 데이터\n",
        "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy() #2개 이상의 값은 []로 묶는다.\n",
        "fish_target = fish['Species'].to_numpy()"
      ],
      "metadata": {
        "id": "lMc0XW5ef9uE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련세트와 테스트 세트로 나눈다.\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state=42)"
      ],
      "metadata": {
        "id": "OpqOxVESgV60"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#표준화 전처리. 꼭 훈련세트에서 학습한 통계 값으로 테스트 세트를 변환하도록 한다!\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "ss.fit(train_input) #훈련세트로 학습\n",
        "train_scaled = ss.transform(train_input)\n",
        "test_scaled = ss.transform(test_input)"
      ],
      "metadata": {
        "id": "p5AnEhPAgbzv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier #사이킷런에서 확률적 경사 하강법을 제공하는 대표적 분류용 클래스"
      ],
      "metadata": {
        "id": "1vM8AcG3g2zt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SGDClassifier(loss='log', max_iter=10, random_state=42) #loss='log'로 손실함수 지정, max_iter로  수행할 에포크 횟수 지정\n",
        "sc.fit(train_scaled, train_target)\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh5XjohihOIj",
        "outputId": "8fe969e9-fc0b-4a3a-c1ea-e2603a27175d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.773109243697479\n",
            "0.775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "확률적 경사 하강법은 점진적 학습이 가능하다. \n",
        "\n",
        "모델을 이어서 훈련하려면 **partial_fit()** 메서드 사용\n"
      ],
      "metadata": {
        "id": "OBUeuXS4i0OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc.partial_fit(train_scaled, train_target) # partial_fit() 메서드는 호출할 때마다 1에포크씩 이어서 훈련할 수 있다.\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled,  test_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBjS3B6vkCVb",
        "outputId": "c7c6aba5-ba4a-449c-86ca-c6207e60bbd5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8151260504201681\n",
            "0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##에포크와 과대/과소적합\n",
        "\n",
        "확률적 경사 하강법을 사용한 모델은 에포크 횟수에 따라 과소적합이나 과대적합이 될 수 있다.\n"
      ],
      "metadata": {
        "id": "ZLK2KMoFkFuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 에포크 횟수가 적으면? -> 모델이 훈련세트를 덜 학습한다.과소적합 모델 가능성이 높다.\n",
        "* 에포크 횟수가 충분히 많으면? -> 훈련 세트를 환전히 학습한다. 과대적합 모델 가능성이 높다."
      ],
      "metadata": {
        "id": "cReEYGnzkgLz"
      }
    }
  ]
}